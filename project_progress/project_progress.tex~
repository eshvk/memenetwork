% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.4 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.4) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.9 - April 2009

\documentclass{acm_proc_article-sp}

\begin{document}
%
% --- Author Metadata here ---
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Meme Tracker}
\subtitle{Social Network Generation and Ranking}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Eshwaran Vijaya Kumar\\
       \affaddr{Dept. of Electrical \& Computer Engineering}\\
       \affaddr{The University of Texas at Austin}\\
       \email{eshwaran@utexas.edu}
       \alignauthor
Saral  Jain\\
   \affaddr{Dept. of Computer Science}\\
   \affaddr{The University of Texas at Austin}\\
   \email{saral@cs.utexas.edu}
   \alignauthor
Prateek Maheshwari \\
   \affaddr{Dept. of Computer Science}\\
   \affaddr{The University of Texas at Austin}\\
   \email{prateekm@utexas.edu}
}


% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{02 November 2011}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Machine Learning, Text Mining}
%A category including the fourth, optional field follows...

\terms{Machine Learning, Text Mining, Mapreduce}

\section{Introduction}
This document serves two purposes: We describe and illustrate our project, explain progress made and talk about challenges that we are currently facing and steps that we plan to take to overcome those. We also illustrate a plan of action to tie up the several components of the project together. 

A meme is a short phrase which originates, travels and mutates in a social network. The meme is a potentially undiscovered path through which information flow takes place in a social network. We would like to automatically extract short phrases which are present in some possibly mutated form in a group of blog posts, group similar phrases together to identify nodes (blog posts) that share edges. This meme-graph is then evaluated as follows: We compare the performance of the meme-graph as a ranking mechanism when compared to a baseline social-graph, the hyperlink graph exploited successfully by Google. 

\section{Meme-Graph Generation}
\subsection{Extraction of a Meme}
The first part of the problem is that of automatically identifying and tracking memes from a corpus of documents that are potentially linked to each other by memes. There are several ways to define a meme \cite{leskovec2009meme},   \cite{kolak2008generating} which impose fundamental assumptions on the design of the entire system. 

Kolak and Schilt \cite{kolak2008generating} describe a scalable technique for generating quotations that are shared between pairs of documents that we employ for the meme generation portion. We describe this in the next section and talk about implementation challenges that we face.

\subsubsection{Sequence Generation Overview}
Given a "clean" corpus of documents (blog posts), we can generate key-value pairs where a key is a short contiguous sequence of characters and value is a pair of documents that contains that key as follows: We first parse each blog posts and generate shingles composed of a few tokens where every token is a space delimited collection of characters. These shingles are used to build an inverted index where the keys are shingles and value is a bucket list. The bucket list is a data structure that is an array of buckets where each bucket contains a unique identifier for a blog post and a position marker which identifies the start of the shingle in the document. The next phase is to merge shingles that are contiguous to each other in a pair of document. This is done as follows: We walk through each document, generate all the shingles that exist in that document. We create a set of sequences as follows: We walk through the shingles in the source document, check if 




 The number of tokens is not fixed to a constant in our system but so that we can tune it empirically. 


  


Leskovec et. al.\cite{leskovec2009meme} make two fundamental assumptions which we feel impose too much of a restriction on the latent network generated: 1) They assume that every meme is demarcated by quotation marks. While, this assumption might be true for a subset of the memes, it would result in a system that fails to capture a large number of memes that don't possess this characteristic. 2) They assume that the evolution of a meme over time can be tracked by the increase in length of the meme. It is not clear why this assumption should be true in general, or why the inverse shouldn't happen. Since we have temporal information, we would like a system that takes that into account. Kolak and Schilit \cite{kolak2008generating} approach a similar problem which can be applied to solve the problem of meme extraction: They mine quotations from books and use them as a way of generating a cross reference across books. However, we feel that their technique for string matching can be improved upon by incorporating more sophisticated approaches for calculating string similarity, like vector space models or language models.

\subsection{Direct String Similarity}
The approach taken by Kolak and Schilit, i.e., generating and extending shingles and then grouping the final results, has a few drawbacks. For one, they set the minimum size of shingles to 8 to reduce the amount of intermediate output. A long shingle length would require sentences containing meme to have a significant and exact overlap, an assumption that is not necessarily true in practice. For example, the following two sentences have the same information content, but would not be detected by the shingles approach for a shingle length greater than 5 (corresponding to the ngram "at the Intel Developer Forum"). One way to overcome this limitation would be to use a smaller minimum size for shingles. However, setting the shingle size lower would increase the amount of intermediate output and the size of each bucket list, and will also increase the amount of time spent extending the shingles for each document in the next phase. Also, in the shingling approach, we generate the shingles irrespective of sentence boundaries, which generates many redundant shingles. (Is this true?)

{\tt The processors were announced in San Jose at the Intel Developer Forum.}

{\tt The new processor was unveiled at the Intel Developer Forum 2003 in San Jose, Calif.}

Another problem is that if the different variations of the meme have been paraphrased, the shingling approach would limit the detectable meme to the longest sequence that two sentences share. Furthermore, if the memes are generated by following a shingling approach, we need to group the memes that share common subsequences into their common "superstring" by grouping the shingles based on the words they share. This problem is equivalent to finding a hamiltonian path in a graph of the meme strings in which the strings are the nodes and all memes that share a substring are directionally connected. The problem of finding Hamiltonian paths in a graph is known to be NP-hard(or complete?) and the solution will not necessarily give accurate results since the meme strings might have an ngram overlap without being originally related.

To avoid these problems we propose an alternate approach to generating and grouping the memes based on a pairwise string similarity computation. For thise approach, we consider a sentence to be the atomic unit that conveys information related to a meme. The idea behind the process is to shortlist the strings from the document collection that might be related to each other and compute one or more syntactic/semantic string similarity measures for those pairs of strings. If the score is above a certain threshold (to be determined experimentally), they will be considered to be the same meme. The process is described below in more detail.

\subsubsection{Preprocessing for Shortlisting Pairs}
In the pairwise string similarity approach described above, we need to shortlist the strings that might potentially be the same meme and compute their similarity. Given enough computing power and time, we could compute the similarity of all the strings in the corpus with each other. However, this is not practically feasible given the large number of strings, and hence we shortlist the strings we will be computing the similarity scores for. To shortlist the strings, we make an assumption that similar strings share at least one ngram (of a size to be determined experimentally) and vice versa, that each pair of string that shared the same ngram is a candidate for similarity computation. We construct an inverted index from ngrams to a postings list containing strings that contain that ngram from the document collection. If we take a cross product of the postings list for each ngram with itself and keep unique string pairs, we get a list of the string pairs that are candidates for similarity computations.

\subsubsection{Experimental Results}
We now present the experimental results from an analysis of the effect of ngram size used for shortlisting pairs on the efficiency and effectiveness of retrieval.

\subsubsection{Grouping}
The next stage is to identify all variants of a single meme and identify the latent social network whose nodes are blog posts and edges are the common meme shared between them. As a first pass, we can try to handle typographical errors, sentence breaks and short changes in the sentence structure using a heuristic that was utilized in \cite{kolak2008generating}. For any given node (post), find all nodes that share a portion or all of the meme; Use this information to discover groups of memes that should ideally be one meme. This allows us to generate the meme-graph which can also be directed based on temporal information.

\subsection{More Sophisticated Extraction Methods}
We feel that the basic string matching algorithm can be improved upon by a number of techniques. One possible approach is to use vector space models (e.g., cosine similarity) to calculate similarity on individual sentences; this will tell us if two sentences are similar without a substring matching. The motivation is to find memes that might be different by simple transpositions of phrases or words, or differ by a few words at most.

Language models provide a statistically sound framework for text modeling and have been popularly used in speech recognition, topic modeling, machine translation etc \cite{ponte1998language}. As another option for calculating string similarity, given the language model of sentence 1, we can try to calculate how likely it is to generate sentence 2, and consider the sentences similar if the generation probability is high.

Another potential approach would be to perform direct text clustering on sentences from a collection of documents to find a set of similar sentences and then construct a shingle table using the documents the sentences belong to.

We will explore these intuitions further in conjunction with insights obtained from existing research in string similarity\cite{achananuparp2008evaluation}, quotation mining and other related areas such as plagiarism detection \cite{kim2009efficient}. 

\section{Graph Clustering}

Once the latent meme-graph has been generated, we first collapse all nodes for posts from the same blog into a single node for that blog. After this step we have reduced the social graph of posts to a social graph of blogs. We then try to analyze the structure of the graph(s) by clustering the nodes using either \cite{blondel2008fast} or \cite{tang2009clustering}. This will help us identify cliques of blogs that have a high information flow between them due to frequent exchanges of memes, and therefore often participate in discussions about the same issues. The algorithm discussed in \cite{blondel2008fast} is a multi-stage algorithm where each node is initially put into its own community and we iteratively merge communities until the objective function defined for the graph attains its local optimum value. Although we have experimentally tested the scalability of the algorithm in another context using large social networks, it would be interesting to try to develop an equivalent Map-Reduce variant of the algorithm. Alternatively, we could also utilize the libScotch library \cite{pellegrini2008scotch} to perform graph clustering in a distributed (albeit non-MapReduce) fashion.
\section{Project Schedule}
We give a brief overview of the organization of the project. We invite the interested reader to refer to the pivotal tracker for the project for more details. 
\begin{description}
\item[Data Preprocessing]The data will have to be initially pre-processed using a HTML parser and be converted to JSON. We have sequential code performing this task right now on a subset of the data. We would like to extend this code and construct a MapReduce version using Python Streaming. 
\item[Basic String Matching Algorithm] We would like to implement the basic string matching algorithm outlined in \cite{kolak2008generating}. This stage will be split into two components: We would first like to develop a sequential version of the algorithm and then extend it further to develop a MapReduce variant. This stage will be used to identify the latent social graph that is generated by exact string matches. Once this is complete, we can optimize this further to perform preliminary groupings in the fashion developed in \cite{kolak2008generating}. Another issue we have not sorted out at this stage is how much of the grouping can be done in a distributed fashion. 
\item [Sophisticated String Matching] There are several interesting threads that we plan to follow in this phase. We could improve upon the grouping in the previous stage by using a Vector Space Model to try to improve the grouping. This should be easily doable in a MapReduce fashion. Some other interesting approaches would be to utilize language models to improve upon the basic string matching that is being done initially. 
This phase will also involve exploring MapReduce models to build these models. 
\item [Graph Clustering] As a first step, we have sequential code available from the authors of \cite{blondel2008fast}. Depending on the size of the social networks generated, we  would have to explore whether or not, we would have to write a MapReduce variant of this algorithm in order to perform clustering. Another issue with this approach is trying to optimally merge graphs generated by different memes in order to construct one single meme-graph. Depending on which of these tasks proves to be harder, we could switch to using a multi-graph approach as outlined in  \cite{tang2009clustering}.
\end{description}



%\end{document}  % This is where a 'short' article might terminate



%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{project_proposal}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\end{document}
